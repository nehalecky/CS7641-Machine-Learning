# SL 5 - Ensemble Learning: Boosting

## Overview

Consider need to detect if email is spam. Instead of assembling a complicated model, we will think of *simpler* rules. 

**Given**:
An email, containing components:
- body
- subject
- to
- from

**Determine**:
- Is spam: YES or NO


### Simple Rules

List a bunch of simple rules that could be useful in identifying spam.

- **body**: contains word *manly* $\rightarrow$  YES
- **from**: your spouse $\rightarrow$  NO
- **body** short length $\rightarrow$  YES
- **body**: only contains urls $\rightarrow$  YES
- **body**: just an image $\rightarrow$  YES
- **body**: contains words belonging to blacklist (misspellings) $\rightarrow$  YES

All of these rules are useful, however, no specific one can determine spam (or not) on its own. We need to find a way to combine them.


### In General 

In general, ensemble learning allow for taking a bunch of simple rules and combining them into a more complex rule that works very well. Similar to decision trees, we build them step by step.

**Algorithmically**

1. Learn over subsets of data, and pick up rules:
	- Learn over first subset of data $\rightarrow$ rule$_1$
	- Learn over another second subset of data $\rightarrow$ rule$_2$
	-  ...
	- Learn over another $n_{th}$ subset of data $\rightarrow$ rule$_n$
2. Combine rules


### In Detail

#### Choosing Subsets

1. Choosing subsets: Uniformly randomly select data, apply a learner
2. Combine: assume each learner is equal, we can take the mean of them.


### QUIZ:

**Given**:
- $N$ points
- $0th$ order polynomials
- Combine: mean
- Subsets are: $N$ disjoint, each with one data point.

What is the output?: **mean**


## Ensemble Learning: Bagging

- 5 subsets of 5 examples, chosen randomly and with replacement.
- Learn a 3rd order polynomial for each
- combine by average

Example demonstrated better performance on testing set than fitting a 4th order polynomial to all of the data!

This particular technique is commonly referred to as *bagging* or *bootstrap aggregation*.

## Ensemble Learning: Boosting

Choosing Subsets:

Instead of selecting subsets *randomly*, we can pick subsets containing *hardest examples*â€”those examples that don't perform well given current rule.

Combine:

Instead of a mean, consider a *weighted mean*.

### Definitions

- Error
	- In *regression*, the squared difference between predicted vs actual values
	- In *classification*, the ratio of the number of errors to the number of examples.

- In the case of classification, instead of considering only the count of matches vs. mismatches (considering each example as discrete), we should also consider the probability of encountering a particular class. 

This shifts the perspective from an:
-  *event-based* (the number of events you get wrong), to 
-  *time-based* (the amount of time you are wrong).

$$ \textrm{P} \left (h(x) \ne c(x) \right)$$

### Weak Learner

A learner that at least does always better than chance. Can be defined as:

$$ \forall_D \textrm{P}_D ( h(x) \ne c(x) ) \le 1/2 - \epsilon $$

### Pseudocode 

**Given**:
Training Set across examples, $i=1 ... n$
$$T = {(x_i, y_i)}$$
where we consider binary classification
$$ y \in ( -1, +1 )$$

Iterate across time, $t$:
For t=1 to T:

- construct distribution: $D_t$
- find weak classifier, $$h_t(x)$$
- with small error
$$\epsilon_t = \textrm{P}_{D_t} ( h_t(x_i) \ne y_i ) < 1/2$$
- output
$$H_{\textrm{final}}$$

#### Distribution Construction

One could consider a base case of the distribution at time $t=1$ as a uniform distribution, like:
$$D_1(i) = 1/n$$

For iterating, one constructs a new distribution, $D_{t+1}$, weighting scheme, such as:

$$D_{t+1}(i) = \frac{D_t(i) e^{-\theta(x_i)}}{Z_t}$$

where 
$$\theta(x_i) = \alpha_t y_i h_t(x_i)$$ 
and
$$\alpha_t =  \frac{1}{2} \ln \frac{1 - \epsilon_t}{ \epsilon_t} $$

and 
$$Z_t$$ 
is some normalization constant at time $t$.
**Question**:
What happens to $D_t(i)$ when $h_t(x_i)$ and $y_i$ agree?
(recall that both $y_i, h_t \in (-1, 1)$)

**Answer**:
It depends, however, it's likely to decrease, thus reducing the weight on this hypothesis in the distribution.

#### Final Hypothesis

The final hypothesis is the weighted sum of the hypotheses to multiplied to the alpha. $\textrm{sgn}$ is the sign function, and returns +1 or -1.

$$ H_{\textrm{final}}(x) =  \textrm{sgn} \left ( \sum_t \alpha_t h_t (x) \right ) $$


## Summary

- ensembles are good
- bagging is good
- combining simple $\rightarrow$ complex
- boosting is *really* good.
	- agnostic to learner
- weak learners
- error (according to distributions)

 
